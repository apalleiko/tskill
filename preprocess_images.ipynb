{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating train & val indices\n",
      "Recomputing scaling functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting all training data info:: 100%|██████████| 100/100 [00:23<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing seperate gripper scaling\n",
      "Computing normal quantile transform\n",
      "Computing linear scaling\n",
      "Adding batch dimension to returned data!\n",
      "100 0\n",
      "freezing state encoder network!\n",
      "/home/mrl/Documents/Projects/tskill/out/PegInsertion/VAE/055/model_best.pt\n",
      "=> Loading checkpoint from local file...\n",
      "load state dict: <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TSkillCVAE(\n",
       "  (decoder): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-4): 5 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (input_embed): Embedding(4, 256)\n",
       "  (stt_encoder): ResnetStateEncoder(\n",
       "    (backbone): Joiner(\n",
       "      (0): Backbone(\n",
       "        (body): IntermediateLayerGetter(\n",
       "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (layer1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): FrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): FrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): FrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): PositionEmbeddingSine()\n",
       "    )\n",
       "  )\n",
       "  (image_proj): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (image_feat_norm): LayerNorm((16, 256), eps=1e-05, elementwise_affine=True)\n",
       "  (enc_action_proj): Linear(in_features=8, out_features=256, bias=True)\n",
       "  (enc_action_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (enc_state_proj): Linear(in_features=18, out_features=256, bias=True)\n",
       "  (enc_state_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (enc_image_proj): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (enc_src_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (enc_tgt_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (enc_z): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (dec_z): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (dec_input_state_proj): Linear(in_features=18, out_features=256, bias=True)\n",
       "  (dec_input_state_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dec_input_z_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dec_src_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dec_tgt_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dec_action_joint_proj): Linear(in_features=256, out_features=7, bias=True)\n",
       "  (dec_action_gripper_proj): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from policy import config\n",
    "from policy.dataset.ms2dataset import get_MS_loaders\n",
    "from policy.checkpoints import CheckpointIO\n",
    "\n",
    "model_dir = \"/home/mrl/Documents/Projects/tskill/out/PegInsertion/VAE/055\"\n",
    "cfg_path = os.path.join(model_dir, \"config.yaml\")\n",
    "cfg = config.load_config(cfg_path, None)\n",
    "\n",
    "# Dataset\n",
    "cfg[\"data\"][\"pad\"] = False\n",
    "cfg[\"data\"][\"augment\"] = False\n",
    "cfg[\"data\"][\"full_seq\"] = False\n",
    "cfg[\"data\"][\"max_count\"] = 100\n",
    "cfg[\"data\"][\"val_split\"] = 0\n",
    "cfg[\"data\"][\"dataset\"] = \"/home/mrl/Documents/Projects/tskill/data/demos/v0/rigid_body/PegInsertionSide-v0/trajectory.rgbd.pd_joint_delta_pos_c256.h5\"\n",
    "\n",
    "# Load only the full episode version of the dataset\n",
    "train_dataset, val_dataset = get_MS_loaders(cfg, return_datasets=True, \n",
    "                                            save_override=True,\n",
    "                                            preshuffle=False,\n",
    "                                            fullseq_override=True,\n",
    "                                            )\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "# Model\n",
    "model = config.get_model(cfg, device=\"cuda\")\n",
    "checkpoint_io = CheckpointIO(model_dir, model=model)\n",
    "load_dict = checkpoint_io.load(\"model_best.pt\")\n",
    "stt_encoder = model.stt_encoder\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 137, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([137, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([137, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (137, 4, 16, 512)\n",
      "==>> img_pe.shape: (137, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 0, 'episode_seed': 0, 'reset_kwargs': {'seed': 0, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 137, 'info': {'elapsed_steps': 137, 'success': True, 'peg_head_pos_at_hole': [-0.008832097053527832, -0.0012859664857387543, -0.0007166117429733276]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_0\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 152, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([152, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([152, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (152, 4, 16, 512)\n",
      "==>> img_pe.shape: (152, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 1, 'episode_seed': 1, 'reset_kwargs': {'seed': 1, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 152, 'info': {'elapsed_steps': 152, 'success': True, 'peg_head_pos_at_hole': [-0.007942840456962585, 0.00291568785905838, -0.0005922839045524597]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_1\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 172, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([172, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([172, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (172, 4, 16, 512)\n",
      "==>> img_pe.shape: (172, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 2, 'episode_seed': 2, 'reset_kwargs': {'seed': 2, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 172, 'info': {'elapsed_steps': 172, 'success': True, 'peg_head_pos_at_hole': [-0.008888423442840576, -0.0008544102311134338, -0.0010154098272323608]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_2\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 135, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([135, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([135, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (135, 4, 16, 512)\n",
      "==>> img_pe.shape: (135, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 3, 'episode_seed': 3, 'reset_kwargs': {'seed': 3, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 135, 'info': {'elapsed_steps': 135, 'success': True, 'peg_head_pos_at_hole': [-0.008440256118774414, -0.00016738474369049072, -0.0006921365857124329]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_3\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 147, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([147, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([147, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (147, 4, 16, 512)\n",
      "==>> img_pe.shape: (147, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 4, 'episode_seed': 5, 'reset_kwargs': {'seed': 5, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 147, 'info': {'elapsed_steps': 147, 'success': True, 'peg_head_pos_at_hole': [-0.007793039083480835, 0.0010588839650154114, -0.0004862174391746521]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_4\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 142, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([142, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([142, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (142, 4, 16, 512)\n",
      "==>> img_pe.shape: (142, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 5, 'episode_seed': 7, 'reset_kwargs': {'seed': 7, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 142, 'info': {'elapsed_steps': 142, 'success': True, 'peg_head_pos_at_hole': [-0.008528679609298706, -0.002360265702009201, -0.00023318827152252197]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_5\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 198, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([198, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([198, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (198, 4, 16, 512)\n",
      "==>> img_pe.shape: (198, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 6, 'episode_seed': 8, 'reset_kwargs': {'seed': 8, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 198, 'info': {'elapsed_steps': 198, 'success': True, 'peg_head_pos_at_hole': [-0.009081631898880005, 0.0018350407481193542, -0.0013401210308074951]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_6\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 149, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([149, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([149, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (149, 4, 16, 512)\n",
      "==>> img_pe.shape: (149, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 7, 'episode_seed': 9, 'reset_kwargs': {'seed': 9, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 149, 'info': {'elapsed_steps': 149, 'success': True, 'peg_head_pos_at_hole': [-0.008961841464042664, -0.0008914098143577576, -0.0006727688014507294]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_7\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 162, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([162, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([162, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (162, 4, 16, 512)\n",
      "==>> img_pe.shape: (162, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 8, 'episode_seed': 11, 'reset_kwargs': {'seed': 11, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 162, 'info': {'elapsed_steps': 162, 'success': True, 'peg_head_pos_at_hole': [-0.00927966833114624, -0.00296626053750515, 4.328042268753052e-05]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_8\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 146, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([146, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([146, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (146, 4, 16, 512)\n",
      "==>> img_pe.shape: (146, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 9, 'episode_seed': 12, 'reset_kwargs': {'seed': 12, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 146, 'info': {'elapsed_steps': 146, 'success': True, 'peg_head_pos_at_hole': [-0.008136019110679626, 0.0009344816207885742, -0.00044392049312591553]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_9\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 164, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([164, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([164, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (164, 4, 16, 512)\n",
      "==>> img_pe.shape: (164, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 10, 'episode_seed': 14, 'reset_kwargs': {'seed': 14, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 164, 'info': {'elapsed_steps': 164, 'success': True, 'peg_head_pos_at_hole': [-0.009254634380340576, 0.00041631609201431274, -0.0004413872957229614]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_10\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 146, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([146, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([146, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (146, 4, 16, 512)\n",
      "==>> img_pe.shape: (146, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 11, 'episode_seed': 15, 'reset_kwargs': {'seed': 15, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 146, 'info': {'elapsed_steps': 146, 'success': True, 'peg_head_pos_at_hole': [-0.008094191551208496, 0.0008790828287601471, -0.0005064159631729126]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_11\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 150, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([150, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([150, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (150, 4, 16, 512)\n",
      "==>> img_pe.shape: (150, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 12, 'episode_seed': 16, 'reset_kwargs': {'seed': 16, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 150, 'info': {'elapsed_steps': 150, 'success': True, 'peg_head_pos_at_hole': [-0.008851736783981323, 0.0002708733081817627, -0.000896010547876358]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_12\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 126, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([126, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([126, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (126, 4, 16, 512)\n",
      "==>> img_pe.shape: (126, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 13, 'episode_seed': 17, 'reset_kwargs': {'seed': 17, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 126, 'info': {'elapsed_steps': 126, 'success': True, 'peg_head_pos_at_hole': [-0.008258044719696045, -8.324719965457916e-05, -0.0007379055023193359]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_13\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 192, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([192, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([192, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (192, 4, 16, 512)\n",
      "==>> img_pe.shape: (192, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 14, 'episode_seed': 18, 'reset_kwargs': {'seed': 18, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 192, 'info': {'elapsed_steps': 192, 'success': True, 'peg_head_pos_at_hole': [-0.009093612432479858, -0.0003836527466773987, -0.0005849003791809082]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_14\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 128, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([128, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([128, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (128, 4, 16, 512)\n",
      "==>> img_pe.shape: (128, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 15, 'episode_seed': 19, 'reset_kwargs': {'seed': 19, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 128, 'info': {'elapsed_steps': 128, 'success': True, 'peg_head_pos_at_hole': [-0.008070334792137146, 0.001116730272769928, -0.0008280239999294281]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_15\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 168, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([168, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([168, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (168, 4, 16, 512)\n",
      "==>> img_pe.shape: (168, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 16, 'episode_seed': 20, 'reset_kwargs': {'seed': 20, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 168, 'info': {'elapsed_steps': 168, 'success': True, 'peg_head_pos_at_hole': [-0.009141102433204651, 0.0011925715953111649, -0.0005211979150772095]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_16\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 188, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([188, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([188, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (188, 4, 16, 512)\n",
      "==>> img_pe.shape: (188, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 17, 'episode_seed': 21, 'reset_kwargs': {'seed': 21, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 188, 'info': {'elapsed_steps': 188, 'success': True, 'peg_head_pos_at_hole': [-0.009094476699829102, 0.0016712397336959839, -0.0008663199841976166]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_17\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 135, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([135, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([135, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (135, 4, 16, 512)\n",
      "==>> img_pe.shape: (135, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 18, 'episode_seed': 22, 'reset_kwargs': {'seed': 22, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 135, 'info': {'elapsed_steps': 135, 'success': True, 'peg_head_pos_at_hole': [-0.008675679564476013, -0.0024025514721870422, -0.0008015409111976624]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_18\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 148, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([148, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([148, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (148, 4, 16, 512)\n",
      "==>> img_pe.shape: (148, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 19, 'episode_seed': 23, 'reset_kwargs': {'seed': 23, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 148, 'info': {'elapsed_steps': 148, 'success': True, 'peg_head_pos_at_hole': [-0.009035944938659668, 0.0007501989603042603, -0.0005782842636108398]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_19\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 199, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([199, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([199, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (199, 4, 16, 512)\n",
      "==>> img_pe.shape: (199, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 20, 'episode_seed': 24, 'reset_kwargs': {'seed': 24, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 199, 'info': {'elapsed_steps': 199, 'success': True, 'peg_head_pos_at_hole': [-0.009499818086624146, -0.0005793273448944092, -0.0007852762937545776]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_20\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 153, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([153, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([153, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (153, 4, 16, 512)\n",
      "==>> img_pe.shape: (153, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 21, 'episode_seed': 25, 'reset_kwargs': {'seed': 25, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 153, 'info': {'elapsed_steps': 153, 'success': True, 'peg_head_pos_at_hole': [-0.008388817310333252, 0.0014884844422340393, -0.0008819848299026489]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_21\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 199, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([199, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([199, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (199, 4, 16, 512)\n",
      "==>> img_pe.shape: (199, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 22, 'episode_seed': 26, 'reset_kwargs': {'seed': 26, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 199, 'info': {'elapsed_steps': 199, 'success': True, 'peg_head_pos_at_hole': [-0.009322106838226318, 0.0012335032224655151, -0.0016079917550086975]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_22\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 156, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([156, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([156, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (156, 4, 16, 512)\n",
      "==>> img_pe.shape: (156, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 23, 'episode_seed': 27, 'reset_kwargs': {'seed': 27, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 156, 'info': {'elapsed_steps': 156, 'success': True, 'peg_head_pos_at_hole': [-0.00897333025932312, 0.000650942325592041, -0.0004349127411842346]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_23\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 132, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([132, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([132, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (132, 4, 16, 512)\n",
      "==>> img_pe.shape: (132, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 24, 'episode_seed': 28, 'reset_kwargs': {'seed': 28, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 132, 'info': {'elapsed_steps': 132, 'success': True, 'peg_head_pos_at_hole': [-0.007958292961120605, 0.0005323514342308044, -0.0006599053740501404]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_24\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 144, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([144, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([144, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (144, 4, 16, 512)\n",
      "==>> img_pe.shape: (144, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 25, 'episode_seed': 29, 'reset_kwargs': {'seed': 29, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 144, 'info': {'elapsed_steps': 144, 'success': True, 'peg_head_pos_at_hole': [-0.008125275373458862, -6.146728992462158e-05, -0.0003276616334915161]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_25\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 183, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([183, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([183, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (183, 4, 16, 512)\n",
      "==>> img_pe.shape: (183, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 26, 'episode_seed': 30, 'reset_kwargs': {'seed': 30, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 183, 'info': {'elapsed_steps': 183, 'success': True, 'peg_head_pos_at_hole': [-0.009081155061721802, -0.0015305876731872559, -0.0018046125769615173]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_26\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 165, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([165, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([165, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (165, 4, 16, 512)\n",
      "==>> img_pe.shape: (165, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 27, 'episode_seed': 31, 'reset_kwargs': {'seed': 31, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 165, 'info': {'elapsed_steps': 165, 'success': True, 'peg_head_pos_at_hole': [-0.00905609130859375, 6.225705146789551e-05, -0.0009322687983512878]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_27\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 152, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([152, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([152, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (152, 4, 16, 512)\n",
      "==>> img_pe.shape: (152, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 28, 'episode_seed': 32, 'reset_kwargs': {'seed': 32, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 152, 'info': {'elapsed_steps': 152, 'success': True, 'peg_head_pos_at_hole': [-0.008675485849380493, 0.0001844167709350586, -0.000616118311882019]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_28\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 149, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([149, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([149, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (149, 4, 16, 512)\n",
      "==>> img_pe.shape: (149, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 29, 'episode_seed': 33, 'reset_kwargs': {'seed': 33, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 149, 'info': {'elapsed_steps': 149, 'success': True, 'peg_head_pos_at_hole': [-0.0088883638381958, 0.0013284683227539062, -0.001498892903327942]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_29\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 164, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([164, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([164, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (164, 4, 16, 512)\n",
      "==>> img_pe.shape: (164, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 30, 'episode_seed': 34, 'reset_kwargs': {'seed': 34, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 164, 'info': {'elapsed_steps': 164, 'success': True, 'peg_head_pos_at_hole': [-0.007631123065948486, 0.001193307340145111, -0.000503838062286377]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_30\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 137, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([137, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([137, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (137, 4, 16, 512)\n",
      "==>> img_pe.shape: (137, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 31, 'episode_seed': 35, 'reset_kwargs': {'seed': 35, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 137, 'info': {'elapsed_steps': 137, 'success': True, 'peg_head_pos_at_hole': [-0.008448153734207153, 0.0008988082408905029, -0.0012508481740951538]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_31\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 139, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([139, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([139, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (139, 4, 16, 512)\n",
      "==>> img_pe.shape: (139, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 32, 'episode_seed': 37, 'reset_kwargs': {'seed': 37, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 139, 'info': {'elapsed_steps': 139, 'success': True, 'peg_head_pos_at_hole': [-0.008144855499267578, 0.0011447519063949585, -0.0006362497806549072]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_32\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 183, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([183, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([183, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (183, 4, 16, 512)\n",
      "==>> img_pe.shape: (183, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 33, 'episode_seed': 38, 'reset_kwargs': {'seed': 38, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 183, 'info': {'elapsed_steps': 183, 'success': True, 'peg_head_pos_at_hole': [-0.009526550769805908, -0.000958392396569252, -0.0005004853010177612]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_33\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 172, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([172, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([172, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (172, 4, 16, 512)\n",
      "==>> img_pe.shape: (172, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 34, 'episode_seed': 39, 'reset_kwargs': {'seed': 39, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 172, 'info': {'elapsed_steps': 172, 'success': True, 'peg_head_pos_at_hole': [-0.009149819612503052, 0.0003849901258945465, -0.0006265789270401001]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_34\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 173, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([173, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([173, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (173, 4, 16, 512)\n",
      "==>> img_pe.shape: (173, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 35, 'episode_seed': 41, 'reset_kwargs': {'seed': 41, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 173, 'info': {'elapsed_steps': 173, 'success': True, 'peg_head_pos_at_hole': [-0.00912591814994812, -0.00020671263337135315, -0.0005664192140102386]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_35\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 155, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([155, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([155, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (155, 4, 16, 512)\n",
      "==>> img_pe.shape: (155, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 36, 'episode_seed': 42, 'reset_kwargs': {'seed': 42, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 155, 'info': {'elapsed_steps': 155, 'success': True, 'peg_head_pos_at_hole': [-0.009064733982086182, 0.00047657638788223267, -0.0013651996850967407]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_36\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 143, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([143, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([143, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (143, 4, 16, 512)\n",
      "==>> img_pe.shape: (143, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 37, 'episode_seed': 43, 'reset_kwargs': {'seed': 43, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 143, 'info': {'elapsed_steps': 143, 'success': True, 'peg_head_pos_at_hole': [-0.007526665925979614, 0.0020776018500328064, -0.00032207369804382324]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_37\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 142, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([142, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([142, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (142, 4, 16, 512)\n",
      "==>> img_pe.shape: (142, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 38, 'episode_seed': 47, 'reset_kwargs': {'seed': 47, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 142, 'info': {'elapsed_steps': 142, 'success': True, 'peg_head_pos_at_hole': [-0.00897035002708435, 0.0007942058145999908, -0.0005371719598770142]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_38\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 140, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([140, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([140, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (140, 4, 16, 512)\n",
      "==>> img_pe.shape: (140, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 39, 'episode_seed': 48, 'reset_kwargs': {'seed': 48, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 140, 'info': {'elapsed_steps': 140, 'success': True, 'peg_head_pos_at_hole': [-0.008047550916671753, 0.0001019500195980072, -0.0007427111268043518]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_39\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 133, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([133, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([133, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (133, 4, 16, 512)\n",
      "==>> img_pe.shape: (133, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 40, 'episode_seed': 50, 'reset_kwargs': {'seed': 50, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 133, 'info': {'elapsed_steps': 133, 'success': True, 'peg_head_pos_at_hole': [-0.008230328559875488, 0.0017418712377548218, -0.0004905238747596741]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_40\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 152, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([152, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([152, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (152, 4, 16, 512)\n",
      "==>> img_pe.shape: (152, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 41, 'episode_seed': 51, 'reset_kwargs': {'seed': 51, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 152, 'info': {'elapsed_steps': 152, 'success': True, 'peg_head_pos_at_hole': [-0.008799701929092407, 0.0004975497722625732, -0.00047197937965393066]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_41\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 146, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([146, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([146, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (146, 4, 16, 512)\n",
      "==>> img_pe.shape: (146, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 42, 'episode_seed': 53, 'reset_kwargs': {'seed': 53, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 146, 'info': {'elapsed_steps': 146, 'success': True, 'peg_head_pos_at_hole': [-0.008549511432647705, 0.0003741700202226639, -0.0005248188972473145]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_42\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 142, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([142, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([142, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (142, 4, 16, 512)\n",
      "==>> img_pe.shape: (142, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 43, 'episode_seed': 54, 'reset_kwargs': {'seed': 54, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 142, 'info': {'elapsed_steps': 142, 'success': True, 'peg_head_pos_at_hole': [-0.008376479148864746, 0.0014025196433067322, -0.0006536319851875305]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_43\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 135, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([135, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([135, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (135, 4, 16, 512)\n",
      "==>> img_pe.shape: (135, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 44, 'episode_seed': 55, 'reset_kwargs': {'seed': 55, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 135, 'info': {'elapsed_steps': 135, 'success': True, 'peg_head_pos_at_hole': [-0.008513092994689941, 0.0006986334919929504, -0.0008633434772491455]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_44\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 188, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([188, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([188, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (188, 4, 16, 512)\n",
      "==>> img_pe.shape: (188, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 45, 'episode_seed': 56, 'reset_kwargs': {'seed': 56, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 188, 'info': {'elapsed_steps': 188, 'success': True, 'peg_head_pos_at_hole': [-0.009164661169052124, -0.00011578947305679321, -0.0007331371307373047]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_45\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 149, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([149, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([149, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (149, 4, 16, 512)\n",
      "==>> img_pe.shape: (149, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 46, 'episode_seed': 57, 'reset_kwargs': {'seed': 57, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 149, 'info': {'elapsed_steps': 149, 'success': True, 'peg_head_pos_at_hole': [-0.00889846682548523, -0.0013861842453479767, -0.0005159825086593628]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_46\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 147, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([147, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([147, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (147, 4, 16, 512)\n",
      "==>> img_pe.shape: (147, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 47, 'episode_seed': 58, 'reset_kwargs': {'seed': 58, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 147, 'info': {'elapsed_steps': 147, 'success': True, 'peg_head_pos_at_hole': [-0.0087679922580719, -0.000491902232170105, -0.0012199804186820984]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_47\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 139, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([139, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([139, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (139, 4, 16, 512)\n",
      "==>> img_pe.shape: (139, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 48, 'episode_seed': 60, 'reset_kwargs': {'seed': 60, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 139, 'info': {'elapsed_steps': 139, 'success': True, 'peg_head_pos_at_hole': [-0.008473813533782959, -0.0008334573358297348, -0.00023350119590759277]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_48\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 196, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([196, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([196, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (196, 4, 16, 512)\n",
      "==>> img_pe.shape: (196, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 49, 'episode_seed': 62, 'reset_kwargs': {'seed': 62, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 196, 'info': {'elapsed_steps': 196, 'success': True, 'peg_head_pos_at_hole': [-0.009390950202941895, -0.0007085129618644714, -0.0016464442014694214]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_49\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 141, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([141, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([141, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (141, 4, 16, 512)\n",
      "==>> img_pe.shape: (141, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 50, 'episode_seed': 63, 'reset_kwargs': {'seed': 63, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 141, 'info': {'elapsed_steps': 141, 'success': True, 'peg_head_pos_at_hole': [-0.007945343852043152, 0.00028748437762260437, -0.0005948320031166077]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_50\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 153, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([153, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([153, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (153, 4, 16, 512)\n",
      "==>> img_pe.shape: (153, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 51, 'episode_seed': 64, 'reset_kwargs': {'seed': 64, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 153, 'info': {'elapsed_steps': 153, 'success': True, 'peg_head_pos_at_hole': [-0.008909791707992554, -0.00035140663385391235, -0.001170419156551361]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_51\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 145, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([145, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([145, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (145, 4, 16, 512)\n",
      "==>> img_pe.shape: (145, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 52, 'episode_seed': 65, 'reset_kwargs': {'seed': 65, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 145, 'info': {'elapsed_steps': 145, 'success': True, 'peg_head_pos_at_hole': [-0.008507028222084045, 0.0006609112024307251, -0.0008498691022396088]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_52\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 144, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([144, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([144, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (144, 4, 16, 512)\n",
      "==>> img_pe.shape: (144, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 53, 'episode_seed': 66, 'reset_kwargs': {'seed': 66, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 144, 'info': {'elapsed_steps': 144, 'success': True, 'peg_head_pos_at_hole': [-0.008551716804504395, -0.0007591098546981812, -0.0003503859043121338]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_53\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 152, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([152, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([152, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (152, 4, 16, 512)\n",
      "==>> img_pe.shape: (152, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 54, 'episode_seed': 67, 'reset_kwargs': {'seed': 67, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 152, 'info': {'elapsed_steps': 152, 'success': True, 'peg_head_pos_at_hole': [-0.00888998806476593, 0.0005201064050197601, -0.0005943328142166138]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_54\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 181, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([181, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([181, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (181, 4, 16, 512)\n",
      "==>> img_pe.shape: (181, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 55, 'episode_seed': 68, 'reset_kwargs': {'seed': 68, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 181, 'info': {'elapsed_steps': 181, 'success': True, 'peg_head_pos_at_hole': [-0.008911818265914917, -0.0006306096911430359, -0.0012314952909946442]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_55\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 123, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([123, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([123, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (123, 4, 16, 512)\n",
      "==>> img_pe.shape: (123, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 56, 'episode_seed': 69, 'reset_kwargs': {'seed': 69, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 123, 'info': {'elapsed_steps': 123, 'success': True, 'peg_head_pos_at_hole': [-0.008221924304962158, -0.0007403716444969177, -0.0009241998195648193]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_56\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 197, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([197, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([197, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (197, 4, 16, 512)\n",
      "==>> img_pe.shape: (197, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 57, 'episode_seed': 71, 'reset_kwargs': {'seed': 71, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 197, 'info': {'elapsed_steps': 197, 'success': True, 'peg_head_pos_at_hole': [-0.009738534688949585, -0.0029575377702713013, -0.0006266534328460693]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_57\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 134, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([134, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([134, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (134, 4, 16, 512)\n",
      "==>> img_pe.shape: (134, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 58, 'episode_seed': 72, 'reset_kwargs': {'seed': 72, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 134, 'info': {'elapsed_steps': 134, 'success': True, 'peg_head_pos_at_hole': [-0.008510291576385498, -0.0013351831585168839, 1.677870750427246e-05]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_58\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 156, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([156, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([156, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (156, 4, 16, 512)\n",
      "==>> img_pe.shape: (156, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 59, 'episode_seed': 73, 'reset_kwargs': {'seed': 73, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 156, 'info': {'elapsed_steps': 156, 'success': True, 'peg_head_pos_at_hole': [-0.009355932474136353, -0.0011219196021556854, -0.0016143396496772766]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_59\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 166, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([166, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([166, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (166, 4, 16, 512)\n",
      "==>> img_pe.shape: (166, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 60, 'episode_seed': 74, 'reset_kwargs': {'seed': 74, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 166, 'info': {'elapsed_steps': 166, 'success': True, 'peg_head_pos_at_hole': [-0.009526357054710388, 0.00018714740872383118, -0.0006408616900444031]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_60\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 127, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([127, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([127, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (127, 4, 16, 512)\n",
      "==>> img_pe.shape: (127, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 61, 'episode_seed': 76, 'reset_kwargs': {'seed': 76, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 127, 'info': {'elapsed_steps': 127, 'success': True, 'peg_head_pos_at_hole': [-0.0081864595413208, 0.0013849139213562012, -0.0010125860571861267]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_61\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 166, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([166, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([166, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (166, 4, 16, 512)\n",
      "==>> img_pe.shape: (166, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 62, 'episode_seed': 77, 'reset_kwargs': {'seed': 77, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 166, 'info': {'elapsed_steps': 166, 'success': True, 'peg_head_pos_at_hole': [-0.009228333830833435, 0.00030846893787384033, -0.0005709081888198853]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_62\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 182, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([182, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([182, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (182, 4, 16, 512)\n",
      "==>> img_pe.shape: (182, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 63, 'episode_seed': 78, 'reset_kwargs': {'seed': 78, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 182, 'info': {'elapsed_steps': 182, 'success': True, 'peg_head_pos_at_hole': [-0.0091896653175354, -0.001532536931335926, -0.00059538334608078]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_63\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 155, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([155, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([155, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (155, 4, 16, 512)\n",
      "==>> img_pe.shape: (155, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 64, 'episode_seed': 79, 'reset_kwargs': {'seed': 79, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 155, 'info': {'elapsed_steps': 155, 'success': True, 'peg_head_pos_at_hole': [-0.008996278047561646, -0.0010501816868782043, -0.001895122230052948]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_64\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 124, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([124, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([124, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (124, 4, 16, 512)\n",
      "==>> img_pe.shape: (124, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 65, 'episode_seed': 80, 'reset_kwargs': {'seed': 80, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 124, 'info': {'elapsed_steps': 124, 'success': True, 'peg_head_pos_at_hole': [-0.008362144231796265, -0.0007714778184890747, -0.000448375940322876]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_65\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 153, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([153, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([153, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (153, 4, 16, 512)\n",
      "==>> img_pe.shape: (153, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 66, 'episode_seed': 82, 'reset_kwargs': {'seed': 82, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 153, 'info': {'elapsed_steps': 153, 'success': True, 'peg_head_pos_at_hole': [-0.00903332233428955, -0.0025025978684425354, 0.0004188120365142822]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_66\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 167, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([167, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([167, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (167, 4, 16, 512)\n",
      "==>> img_pe.shape: (167, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 67, 'episode_seed': 83, 'reset_kwargs': {'seed': 83, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 167, 'info': {'elapsed_steps': 167, 'success': True, 'peg_head_pos_at_hole': [-0.008904039859771729, -0.0003050193190574646, -0.0006161406636238098]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_67\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 150, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([150, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([150, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (150, 4, 16, 512)\n",
      "==>> img_pe.shape: (150, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 68, 'episode_seed': 84, 'reset_kwargs': {'seed': 84, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 150, 'info': {'elapsed_steps': 150, 'success': True, 'peg_head_pos_at_hole': [-0.00801047682762146, 0.0016495510935783386, -0.000357016921043396]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_68\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 121, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([121, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([121, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (121, 4, 16, 512)\n",
      "==>> img_pe.shape: (121, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 69, 'episode_seed': 85, 'reset_kwargs': {'seed': 85, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 121, 'info': {'elapsed_steps': 121, 'success': True, 'peg_head_pos_at_hole': [-0.008237883448600769, 0.0005600005388259888, -0.0005017220973968506]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_69\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 127, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([127, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([127, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (127, 4, 16, 512)\n",
      "==>> img_pe.shape: (127, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 70, 'episode_seed': 86, 'reset_kwargs': {'seed': 86, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 127, 'info': {'elapsed_steps': 127, 'success': True, 'peg_head_pos_at_hole': [-0.007880374789237976, 0.002468697726726532, -0.0005708932876586914]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_70\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 170, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([170, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([170, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (170, 4, 16, 512)\n",
      "==>> img_pe.shape: (170, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 71, 'episode_seed': 87, 'reset_kwargs': {'seed': 87, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 170, 'info': {'elapsed_steps': 170, 'success': True, 'peg_head_pos_at_hole': [-0.00915566086769104, 0.0009863600134849548, -0.0007160454988479614]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_71\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 143, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([143, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([143, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (143, 4, 16, 512)\n",
      "==>> img_pe.shape: (143, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 72, 'episode_seed': 88, 'reset_kwargs': {'seed': 88, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 143, 'info': {'elapsed_steps': 143, 'success': True, 'peg_head_pos_at_hole': [-0.00896066427230835, -0.0028798729181289673, 0.0003196895122528076]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_72\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 136, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([136, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([136, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (136, 4, 16, 512)\n",
      "==>> img_pe.shape: (136, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 73, 'episode_seed': 91, 'reset_kwargs': {'seed': 91, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 136, 'info': {'elapsed_steps': 136, 'success': True, 'peg_head_pos_at_hole': [-0.008646994829177856, -7.725879549980164e-05, -0.0005445592105388641]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_73\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 140, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([140, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([140, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (140, 4, 16, 512)\n",
      "==>> img_pe.shape: (140, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 74, 'episode_seed': 92, 'reset_kwargs': {'seed': 92, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 140, 'info': {'elapsed_steps': 140, 'success': True, 'peg_head_pos_at_hole': [-0.008561000227928162, 0.0005827434360980988, -0.0015030279755592346]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_74\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 164, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([164, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([164, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (164, 4, 16, 512)\n",
      "==>> img_pe.shape: (164, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 75, 'episode_seed': 94, 'reset_kwargs': {'seed': 94, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 164, 'info': {'elapsed_steps': 164, 'success': True, 'peg_head_pos_at_hole': [-0.008688658475875854, 0.0008668489754199982, -0.0004773139953613281]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_75\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 199, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([199, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([199, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (199, 4, 16, 512)\n",
      "==>> img_pe.shape: (199, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 76, 'episode_seed': 95, 'reset_kwargs': {'seed': 95, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 199, 'info': {'elapsed_steps': 199, 'success': True, 'peg_head_pos_at_hole': [-0.009509503841400146, -0.0009071603417396545, -0.0005849003791809082]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_76\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 180, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([180, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([180, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (180, 4, 16, 512)\n",
      "==>> img_pe.shape: (180, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 77, 'episode_seed': 96, 'reset_kwargs': {'seed': 96, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 180, 'info': {'elapsed_steps': 180, 'success': True, 'peg_head_pos_at_hole': [-0.008750170469284058, 0.0007981359958648682, -0.0007942467927932739]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_77\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 144, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([144, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([144, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (144, 4, 16, 512)\n",
      "==>> img_pe.shape: (144, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 78, 'episode_seed': 97, 'reset_kwargs': {'seed': 97, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 144, 'info': {'elapsed_steps': 144, 'success': True, 'peg_head_pos_at_hole': [-0.008648306131362915, -0.0007941499352455139, -0.001230381429195404]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_78\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 141, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([141, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([141, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (141, 4, 16, 512)\n",
      "==>> img_pe.shape: (141, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 79, 'episode_seed': 98, 'reset_kwargs': {'seed': 98, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 141, 'info': {'elapsed_steps': 141, 'success': True, 'peg_head_pos_at_hole': [-0.00839012861251831, 0.0005037114024162292, -0.0011492371559143066]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_79\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 198, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([198, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([198, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (198, 4, 16, 512)\n",
      "==>> img_pe.shape: (198, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 80, 'episode_seed': 99, 'reset_kwargs': {'seed': 99, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 198, 'info': {'elapsed_steps': 198, 'success': True, 'peg_head_pos_at_hole': [-0.008675992488861084, 0.0012528561055660248, -0.0003866329789161682]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_80\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 145, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([145, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([145, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (145, 4, 16, 512)\n",
      "==>> img_pe.shape: (145, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 81, 'episode_seed': 100, 'reset_kwargs': {'seed': 100, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 145, 'info': {'elapsed_steps': 145, 'success': True, 'peg_head_pos_at_hole': [-0.00859840214252472, -0.0007245875895023346, -0.0007769167423248291]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_81\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 162, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([162, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([162, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (162, 4, 16, 512)\n",
      "==>> img_pe.shape: (162, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 82, 'episode_seed': 101, 'reset_kwargs': {'seed': 101, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 162, 'info': {'elapsed_steps': 162, 'success': True, 'peg_head_pos_at_hole': [-0.008094608783721924, 0.0006913021206855774, -0.0008635744452476501]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_82\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 133, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([133, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([133, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (133, 4, 16, 512)\n",
      "==>> img_pe.shape: (133, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 83, 'episode_seed': 102, 'reset_kwargs': {'seed': 102, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 133, 'info': {'elapsed_steps': 133, 'success': True, 'peg_head_pos_at_hole': [-0.008323967456817627, 0.00038595497608184814, -0.0006482824683189392]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_83\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 190, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([190, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([190, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (190, 4, 16, 512)\n",
      "==>> img_pe.shape: (190, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 84, 'episode_seed': 104, 'reset_kwargs': {'seed': 104, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 190, 'info': {'elapsed_steps': 190, 'success': True, 'peg_head_pos_at_hole': [-0.009424149990081787, 0.0006459951400756836, -0.0006557032465934753]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_84\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 149, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([149, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([149, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (149, 4, 16, 512)\n",
      "==>> img_pe.shape: (149, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 85, 'episode_seed': 106, 'reset_kwargs': {'seed': 106, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 149, 'info': {'elapsed_steps': 149, 'success': True, 'peg_head_pos_at_hole': [-0.00827091932296753, -0.0013414844870567322, 2.9355287551879883e-05]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_85\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 143, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([143, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([143, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (143, 4, 16, 512)\n",
      "==>> img_pe.shape: (143, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 86, 'episode_seed': 107, 'reset_kwargs': {'seed': 107, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 143, 'info': {'elapsed_steps': 143, 'success': True, 'peg_head_pos_at_hole': [-0.008776217699050903, 0.0009893029928207397, -0.0009092241525650024]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_86\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 175, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([175, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([175, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (175, 4, 16, 512)\n",
      "==>> img_pe.shape: (175, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 87, 'episode_seed': 108, 'reset_kwargs': {'seed': 108, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 175, 'info': {'elapsed_steps': 175, 'success': True, 'peg_head_pos_at_hole': [-0.009351730346679688, -0.0029664337635040283, -0.0005620978772640228]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_87\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 165, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([165, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([165, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (165, 4, 16, 512)\n",
      "==>> img_pe.shape: (165, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 88, 'episode_seed': 109, 'reset_kwargs': {'seed': 109, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 165, 'info': {'elapsed_steps': 165, 'success': True, 'peg_head_pos_at_hole': [-0.008978992700576782, -0.0014636889100074768, -0.0005759745836257935]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_88\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 134, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([134, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([134, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (134, 4, 16, 512)\n",
      "==>> img_pe.shape: (134, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 89, 'episode_seed': 110, 'reset_kwargs': {'seed': 110, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 134, 'info': {'elapsed_steps': 134, 'success': True, 'peg_head_pos_at_hole': [-0.00824543833732605, 0.0005820617079734802, -0.0004499182105064392]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_89\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 162, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([162, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([162, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (162, 4, 16, 512)\n",
      "==>> img_pe.shape: (162, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 90, 'episode_seed': 111, 'reset_kwargs': {'seed': 111, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 162, 'info': {'elapsed_steps': 162, 'success': True, 'peg_head_pos_at_hole': [-0.00899718701839447, -0.001054856926202774, -0.0020030736923217773]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_90\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 191, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([191, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([191, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (191, 4, 16, 512)\n",
      "==>> img_pe.shape: (191, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 91, 'episode_seed': 112, 'reset_kwargs': {'seed': 112, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 191, 'info': {'elapsed_steps': 191, 'success': True, 'peg_head_pos_at_hole': [-0.009491294622421265, -7.903575897216797e-05, -0.0005288049578666687]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_91\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 190, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([190, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([190, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (190, 4, 16, 512)\n",
      "==>> img_pe.shape: (190, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 92, 'episode_seed': 114, 'reset_kwargs': {'seed': 114, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 190, 'info': {'elapsed_steps': 190, 'success': True, 'peg_head_pos_at_hole': [-0.009523749351501465, -0.0003774315118789673, -0.0005991756916046143]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_92\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 136, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([136, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([136, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (136, 4, 16, 512)\n",
      "==>> img_pe.shape: (136, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 93, 'episode_seed': 115, 'reset_kwargs': {'seed': 115, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 136, 'info': {'elapsed_steps': 136, 'success': True, 'peg_head_pos_at_hole': [-0.008521825075149536, 0.0006095767021179199, -0.001109987497329712]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_93\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 187, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([187, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([187, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (187, 4, 16, 512)\n",
      "==>> img_pe.shape: (187, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 94, 'episode_seed': 116, 'reset_kwargs': {'seed': 116, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 187, 'info': {'elapsed_steps': 187, 'success': True, 'peg_head_pos_at_hole': [-0.009263470768928528, -0.00012357905507087708, -0.0003834925591945648]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_94\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 147, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([147, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([147, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (147, 4, 16, 512)\n",
      "==>> img_pe.shape: (147, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 95, 'episode_seed': 117, 'reset_kwargs': {'seed': 117, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 147, 'info': {'elapsed_steps': 147, 'success': True, 'peg_head_pos_at_hole': [-0.008472874760627747, 0.0009452402591705322, -0.0006302744150161743]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_95\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 145, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([145, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([145, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (145, 4, 16, 512)\n",
      "==>> img_pe.shape: (145, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 96, 'episode_seed': 119, 'reset_kwargs': {'seed': 119, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 145, 'info': {'elapsed_steps': 145, 'success': True, 'peg_head_pos_at_hole': [-0.008262395858764648, 0.0015666261315345764, -0.0012783259153366089]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_96\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 144, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([144, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([144, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (144, 4, 16, 512)\n",
      "==>> img_pe.shape: (144, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 97, 'episode_seed': 120, 'reset_kwargs': {'seed': 120, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 144, 'info': {'elapsed_steps': 144, 'success': True, 'peg_head_pos_at_hole': [-0.008776694536209106, 0.0004869326949119568, -0.0005629658699035645]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_97\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 139, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([139, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([139, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (139, 4, 16, 512)\n",
      "==>> img_pe.shape: (139, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 98, 'episode_seed': 121, 'reset_kwargs': {'seed': 121, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 139, 'info': {'elapsed_steps': 139, 'success': True, 'peg_head_pos_at_hole': [-0.008212566375732422, -0.000987805426120758, -0.0004499703645706177]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_98\" (4 members)>\n",
      "==>> train_dataset[i]: dict_keys(['state', 'seq_pad_mask', 'skill_pad_mask', 'actions', 'rgb', 'dec_src_mask', 'dec_mem_mask', 'dec_tgt_mask', 'enc_src_mask', 'enc_mem_mask', 'enc_tgt_mask'])\n",
      "==>> rgb.shape: torch.Size([1, 133, 4, 3, 128, 128])\n",
      "==>> img_feat.shape: torch.Size([133, 1, 4, 16, 512])\n",
      "==>> img_pe.shape: torch.Size([133, 1, 4, 16, 256])\n",
      "==>> img_feat.shape: (133, 4, 16, 512)\n",
      "==>> img_pe.shape: (133, 4, 16, 256)\n",
      "==>> eps: {'episode_id': 99, 'episode_seed': 122, 'reset_kwargs': {'seed': 122, 'options': {}}, 'control_mode': 'pd_joint_delta_pos', 'elapsed_steps': 133, 'info': {'elapsed_steps': 133, 'success': True, 'peg_head_pos_at_hole': [-0.007851719856262207, 0.0015762709081172943, -0.00038979947566986084]}}\n",
      "==>> trajectory: <HDF5 group \"/traj_99\" (4 members)>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "dataset_path = cfg[\"data\"][\"dataset\"]\n",
    "train_dataset.data.close()\n",
    "val_dataset.data.close()\n",
    "dataset_file = h5py.File(dataset_path, \"r+\")\n",
    "train_dataset.data = dataset_file\n",
    "for i in range(len(train_dataset)):\n",
    "    print(f\"==>> train_dataset[i]: {train_dataset[i].keys()}\")\n",
    "    rgb = train_dataset[i][\"rgb\"].to(model._device)\n",
    "    print(f\"==>> rgb.shape: {rgb.shape}\")\n",
    "    with torch.no_grad():\n",
    "        img_feat, img_pe = stt_encoder(rgb)\n",
    "        print(f\"==>> img_feat.shape: {img_feat.shape}\")\n",
    "        print(f\"==>> img_pe.shape: {img_pe.shape}\")\n",
    "    img_feat, img_pe = img_feat[:,0,...].detach().cpu().numpy(), img_pe[:,0,...].detach().cpu().numpy()\n",
    "    print(f\"==>> img_feat.shape: {img_feat.shape}\")\n",
    "    print(f\"==>> img_pe.shape: {img_pe.shape}\")\n",
    "    eps = train_dataset.episodes[train_dataset.owned_indices[i]]\n",
    "    print(f\"==>> eps: {eps}\")\n",
    "    trajectory = dataset_file[f\"traj_{eps['episode_id']}\"]\n",
    "    print(f\"==>> trajectory: {trajectory}\")\n",
    "    del trajectory[\"obs\"][\"image\"]\n",
    "    trajectory.create_dataset(\"obs/resnet18/img_feat\",\n",
    "                              data=img_feat,\n",
    "                              dtype=img_feat.dtype,\n",
    "                              compression=\"gzip\",\n",
    "                            compression_opts=5,),\n",
    "    trajectory.create_dataset(\"obs/resnet18/img_pe\",\n",
    "                              data=img_pe,\n",
    "                              dtype=img_pe.dtype,\n",
    "                              compression=\"gzip\",\n",
    "                              compression_opts=5,)\n",
    "\n",
    "dataset_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tskill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
