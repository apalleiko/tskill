{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSkillCVAE(\n",
      "  (decoder): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-7): 8 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-3): 4 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (stt_encoder): ResnetStateEncoder(\n",
      "    (backbone): Joiner(\n",
      "      (0): Backbone(\n",
      "        (body): IntermediateLayerGetter(\n",
      "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "          (layer1): Sequential(\n",
      "            (0): BasicBlock(\n",
      "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn2): FrozenBatchNorm2d()\n",
      "            )\n",
      "            (1): BasicBlock(\n",
      "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn2): FrozenBatchNorm2d()\n",
      "            )\n",
      "          )\n",
      "          (layer2): Sequential(\n",
      "            (0): BasicBlock(\n",
      "              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn2): FrozenBatchNorm2d()\n",
      "              (downsample): Sequential(\n",
      "                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (1): FrozenBatchNorm2d()\n",
      "              )\n",
      "            )\n",
      "            (1): BasicBlock(\n",
      "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn2): FrozenBatchNorm2d()\n",
      "            )\n",
      "          )\n",
      "          (layer3): Sequential(\n",
      "            (0): BasicBlock(\n",
      "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn2): FrozenBatchNorm2d()\n",
      "              (downsample): Sequential(\n",
      "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (1): FrozenBatchNorm2d()\n",
      "              )\n",
      "            )\n",
      "            (1): BasicBlock(\n",
      "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn2): FrozenBatchNorm2d()\n",
      "            )\n",
      "          )\n",
      "          (layer4): Sequential(\n",
      "            (0): BasicBlock(\n",
      "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn2): FrozenBatchNorm2d()\n",
      "              (downsample): Sequential(\n",
      "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (1): FrozenBatchNorm2d()\n",
      "              )\n",
      "            )\n",
      "            (1): BasicBlock(\n",
      "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn2): FrozenBatchNorm2d()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): PositionEmbeddingSine()\n",
      "    )\n",
      "    (image_proj): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (image_feat_norm): LayerNorm((32, 256), eps=1e-05, elementwise_affine=True)\n",
      "  (enc_action_proj): Linear(in_features=8, out_features=256, bias=True)\n",
      "  (enc_action_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (enc_state_proj): Linear(in_features=9, out_features=256, bias=True)\n",
      "  (enc_state_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (enc_image_proj): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (enc_input_emb): Embedding(3, 256)\n",
      "  (enc_z): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (dec_z): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (dec_input_state_proj): Linear(in_features=9, out_features=256, bias=True)\n",
      "  (dec_input_state_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (dec_input_z_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (dec_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (dec_action_proj): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=32, out_features=8, bias=True)\n",
      "  )\n",
      "  (dec_inputs_pe): Embedding(3, 256)\n",
      ")\n",
      "/home/mrl/Documents/Projects/tskill/out/PegInsertion/test2/model_best.pt\n",
      "=> Loading checkpoint from local file...\n",
      "load state dict: <All keys matched successfully>\n",
      "load state dict: None\n",
      "Current best validation metric (act_loss): 0.23957225\n",
      "Number of trainable parameters: 22.95M\n",
      "Number of total parameters: 34.12M\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from policy import config\n",
    "from policy.checkpoints import CheckpointIO\n",
    "from policy.dataset.ms2dataset import get_MS_loaders\n",
    "from policy.skill.training import Trainer\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "out_dir = \"/home/mrl/Documents/Projects/tskill/out/PegInsertion/test2\"\n",
    "default_cfg_path = os.path.join(out_dir, \"config.yaml\")\n",
    "\n",
    "cfg = config.load_config(default_cfg_path)\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")\n",
    "\n",
    "lr = cfg[\"training\"].get(\"lr\", 1e-3)\n",
    "weight_decay = cfg[\"training\"].get(\"weight_decay\", 1e-4)\n",
    "backup_every = cfg[\"training\"][\"backup_every\"]\n",
    "max_it = cfg[\"training\"][\"max_it\"]\n",
    "model_selection_metric = cfg[\"training\"][\"model_selection_metric\"]\n",
    "if cfg[\"training\"][\"model_selection_mode\"] == \"maximize\":\n",
    "    model_selection_sign = 1\n",
    "elif cfg[\"training\"][\"model_selection_mode\"] == \"minimize\":\n",
    "    model_selection_sign = -1\n",
    "else:\n",
    "    raise ValueError(\"model_selection_mode must be \" \"either maximize or minimize.\")\n",
    "\n",
    "# os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# copy config to output directory\n",
    "# shutil.copyfile(default_cfg_path, os.path.join(out_dir, \"config.yaml\"))\n",
    "\n",
    "cfg[\"training\"][\"batch_size\"] = 1\n",
    "cfg[\"training\"][\"val_batch_size\"] = 1\n",
    "\n",
    "# Model\n",
    "model = config.get_model(cfg, device=device)\n",
    "print(model)\n",
    "\n",
    "# Intialize training\n",
    "param_dicts = [{\"params\": [p for n, p in model.named_parameters() if \"stt_encoder\" not in n and p.requires_grad]}]\n",
    "if cfg[\"training\"][\"lr_state_encoder\"] > 0:\n",
    "    param_dicts.append({\n",
    "        \"params\": [p for n, p in model.named_parameters() if \"stt_encoder\" in n and p.requires_grad],\n",
    "        \"lr\": cfg[\"training\"][\"lr_state_encoder\"],\n",
    "    })\n",
    "\n",
    "n_p = 0\n",
    "for d in param_dicts:\n",
    "    n_p += sum([p.numel() for p in d[\"params\"]])\n",
    "\n",
    "optimizer = torch.optim.AdamW(param_dicts, lr=lr,\n",
    "                                weight_decay=weight_decay)    \n",
    "\n",
    "lr_decay = cfg[\"training\"].get(\"lr_decay\",1)\n",
    "if lr_decay < 1:\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay)\n",
    "\n",
    "trainer: Trainer = config.get_trainer(model, optimizer, cfg, device=device)\n",
    "checkpoint_io = CheckpointIO(out_dir, model=model, optimizer=optimizer)\n",
    "\n",
    "try:\n",
    "    load_dict = checkpoint_io.load(\"model_best.pt\")\n",
    "except FileExistsError:\n",
    "    load_dict = dict()\n",
    "\n",
    "epoch_it = load_dict.get(\"epoch_it\", 0)\n",
    "it = load_dict.get(\"it\", 0)\n",
    "\n",
    "metric_val_best = load_dict.get(\"loss_val_best\", -model_selection_sign * np.inf)\n",
    "\n",
    "if metric_val_best == np.inf or metric_val_best == -np.inf:\n",
    "    metric_val_best = -model_selection_sign * np.inf\n",
    "print(\n",
    "    \"Current best validation metric (%s): %.8f\"\n",
    "    % (model_selection_metric, metric_val_best)\n",
    ")\n",
    "\n",
    "# Shorthands\n",
    "print_every = cfg[\"training\"][\"print_every\"]\n",
    "checkpoint_every = cfg[\"training\"][\"checkpoint_every\"]\n",
    "validate_every = cfg[\"training\"][\"validate_every\"]\n",
    "visualize_every = cfg[\"training\"][\"visualize_every\"]\n",
    "\n",
    "# Print model\n",
    "nparameters = sum(p.numel() for p in model.parameters())\n",
    "n_trainable_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "assert n_trainable_parameters == n_p, \"Number of trainable params does not match param dicts\"\n",
    "\n",
    "print(\"Number of trainable parameters: %.2fM\" % (n_trainable_parameters/1e6,))\n",
    "print(\"Number of total parameters: %.2fM\" % (nparameters/1e6,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing linear scaling\n",
      "Replacing existing action scaling file\n",
      "Replacing existing train/val index file\n",
      "Shuffling: False\n",
      "Iterating through training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:26<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting all actions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing seperate gripper scaling\n",
      "Computing action norm\n",
      "Replacing existing action scaling file\n",
      "Loading indices from file: out/PegInsertion/action_scaling_test/train_val_indices.pickle\n",
      "Shuffling: False\n",
      "Iterating through training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 25/45 [00:14<00:11,  1.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m acts_i \u001b[38;5;241m=\u001b[39m acts[\u001b[38;5;241m0\u001b[39m,i,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     33\u001b[0m qpos_i \u001b[38;5;241m=\u001b[39m qpos[\u001b[38;5;241m0\u001b[39m,i,:]\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43macts_i\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     35\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_histogram(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mep_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_all_acts_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, acts_i, i)\n\u001b[1;32m     36\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_histogram(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mep_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_all_qpos_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, qpos_i, i)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "act_scaling = (1, \"robust_scaler\",\"normal\",\"uniform\")\n",
    "state_scaling = (1, \"robust_scaler\", \"normal\", \"uniform\")\n",
    "summary_dir = \"out/PegInsertion/action_scaling_test\"\n",
    "os.makedirs(summary_dir, exist_ok=True)\n",
    "writer = SummaryWriter(summary_dir)\n",
    "t0 = time.time()\n",
    "for k in range(len(act_scaling)):\n",
    "    s = act_scaling[k]\n",
    "    s2 = state_scaling[k]\n",
    "    cfg[\"data\"][\"action_scaling\"] = s\n",
    "    cfg[\"data\"][\"state_scaling\"] = s2\n",
    "    cfg[\"data\"][\"gripper_scaling\"] = False\n",
    "    cfg[\"training\"][\"out_dir\"] = summary_dir\n",
    "    if k > 0:\n",
    "        train_loader, val_loader = get_MS_loaders(cfg, indices=\"file\", shuffle=False)\n",
    "    else:\n",
    "        train_loader, val_loader = get_MS_loaders(cfg, shuffle=False)\n",
    "    # Dataset\n",
    "    \n",
    "    print(\"Iterating through training set...\")\n",
    "    ep = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        it += 1\n",
    "        ep += 1  \n",
    "        acts = batch[\"actions\"]\n",
    "        qpos = batch[\"state\"]\n",
    "        bs, seq, act_dim = acts.shape\n",
    "        _, _, q_dim = qpos.shape\n",
    "        for i in range(seq):\n",
    "            acts_i = acts[0,i,:-1]\n",
    "            qpos_i = qpos[0,i,:]\n",
    "            if torch.nonzero(acts_i).shape[0] > 0:\n",
    "                writer.add_histogram(f'ep_{ep}_all_acts_{k}', acts_i, i)\n",
    "                writer.add_histogram(f'ep_{ep}_all_qpos_{k}', qpos_i, i)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for a in range(act_dim):\n",
    "            acts_a = acts[0,:,a]\n",
    "            writer.add_histogram(f'ep_{ep}_act_{a}', acts_a, k)\n",
    "        for q in range(q_dim):\n",
    "            qpos_q = qpos[0,:,q]\n",
    "            writer.add_histogram(f'ep_{ep}_qpos_{q}', qpos_q, k)\n",
    "\n",
    "        # losses, met = trainer.train_step(batch)\n",
    "\n",
    "        # Tensorboard model graph\n",
    "        # if args.debug:\n",
    "        #     trace_batch = dict()\n",
    "        #     for k,v in batch.items():\n",
    "        #         if \"skill\" not in k:\n",
    "        #             trace_batch[k] = v[:,:5,...]\n",
    "        #         else:\n",
    "        #             trace_batch[k] = v[:,0:1,...]\n",
    "        #     writer.add_graph(model, batch, use_strict_trace=False)\n",
    "\n",
    "        # metrics = {f\"train/{k}\": v for k, v in losses.items()}\n",
    "        # metrics.update({f\"train/metrics/{k}\": v for k, v in met.items()})\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tskill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
