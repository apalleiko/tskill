{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data info file\n",
      "Using override indices\n",
      "Loading action and state scaling from file\n",
      "Adding batch dimension to returned data!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "\n",
    "from policy import config\n",
    "from policy.dataset.ms2dataset import get_MS_loaders\n",
    "from policy.checkpoints import CheckpointIO\n",
    "\n",
    "model_dir = \"/home/mrl/Documents/Projects/tskill/out/PegInsertion/031\"\n",
    "\n",
    "cfg_path = os.path.join(model_dir, \"config.yaml\")\n",
    "# cfg_path = \"/home/mrl/Documents/Projects/tskill/assets/skill/default.yaml\"\n",
    "cfg = config.load_config(cfg_path, None)\n",
    "\n",
    "index_path = os.path.join(model_dir, \"data_info.pickle\")\n",
    "with open(index_path, 'rb') as f:\n",
    "    data_info = pickle.load(f)\n",
    "\n",
    "# Dataset\n",
    "cfg[\"data\"][\"pad\"] = True\n",
    "cfg[\"training\"][\"n_workers\"] = 2\n",
    "cfg[\"data\"][\"augment\"] = False\n",
    "cfg[\"data\"][\"augmentation\"][\"image_aug\"] = False\n",
    "cfg[\"data\"][\"augmentation\"][\"subsequence_rate\"] = 1\n",
    "cfg[\"data\"][\"full_seq\"] = False\n",
    "cfg[\"data\"][\"dataset\"] = \"/home/mrl/Documents/Projects/tskill/data/demos/v0/rigid_body/PegInsertionSide-v0/trajectory.rgbd.pd_joint_delta_pos3.h5\"\n",
    "\n",
    "# Load only the full episode version of the dataset\n",
    "if \"train_ep_indices\" not in data_info.keys():\n",
    "    train_idx, val_idx = data_info[\"train_indices\"], data_info[\"val_indices\"]\n",
    "else:\n",
    "    train_idx, val_idx = data_info[\"train_ep_indices\"], data_info[\"val_ep_indices\"]\n",
    "train_dataset, val_dataset = get_MS_loaders(cfg, return_datasets=True, \n",
    "                                            indices=(train_idx, val_idx),\n",
    "                                            save_override=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freezing state encoder network!\n",
      "/home/mrl/Documents/Projects/tskill/out/PegInsertion/031/model_best.pt\n",
      "=> Loading checkpoint from local file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/mrl/anaconda3/envs/tskill/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load state dict: <All keys matched successfully>\n",
      "Using Training Dataset\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = config.get_model(cfg, device=\"cpu\")\n",
    "checkpoint_io = CheckpointIO(model_dir, model=model)\n",
    "load_dict = checkpoint_io.load(\"model_best.pt\")\n",
    "model.eval()\n",
    "\n",
    "train = True\n",
    "if not train:\n",
    "    dataset = val_dataset\n",
    "    print(\"Using Validation Dataset\")\n",
    "    idxs = val_idx\n",
    "else:\n",
    "    dataset = train_dataset\n",
    "    print(\"Using Training Dataset\")\n",
    "    idxs = train_idx\n",
    "\n",
    "\n",
    "class AttentionHook:\n",
    "    def __init__(self):\n",
    "        self.attention_weights = []\n",
    "        self.attention = []\n",
    "        self.inputs = []\n",
    "\n",
    "    def __call__(self, module, input, output):\n",
    "        self.attention.append(output[0])\n",
    "        self.attention_weights.append(output[1])\n",
    "        self.inputs.append(input)\n",
    "\n",
    "\n",
    "def visualize_attention_weights(attention_weights, layer_name, layer_num, attn):\n",
    "    avg_attention = attention_weights.mean(dim=0).abs().detach().cpu().numpy()\n",
    "    print(avg_attention.shape)\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(avg_attention, annot=False, cmap='YlGnBu')\n",
    "    ax = fig.axes[0]\n",
    "    plt.xlabel('Input Sequence')\n",
    "    plt.ylabel('Input Sequence')\n",
    "    plt.title(f'{layer_name} Layer {layer_num} {attn} Attention Weight Visualization')\n",
    "    \n",
    "    # plt.xticks(range(avg_attention.shape[1]), range(avg_attention.shape[1]), rotation=90)\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(avg_attention.shape[0]/6))\n",
    "    ax.xaxis.set_major_formatter('{x:.0f}')\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(avg_attention.shape[0]/6))\n",
    "    ax.yaxis.set_major_formatter('{x:.0f}')\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(10))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_attention(attention, input_len, layer_name, layer_num, attn):\n",
    "    avg_attention = attention.mean(dim=-1).abs().squeeze().detach().cpu().numpy()\n",
    "    if len(avg_attention.shape) != 0:\n",
    "        print(avg_attention.shape)\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        sns.barplot(avg_attention)\n",
    "        \n",
    "        plt.xlabel('Input Sequence')\n",
    "        plt.ylabel('Attention')\n",
    "        plt.title(f'{layer_name} Layer {layer_num} {attn} Attention Visualization')\n",
    "        \n",
    "        plt.xticks(range(input_len), range(input_len), rotation=90)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Register hooks\n",
    "dec_enc_hooks = []\n",
    "dec_dec_hooks = []\n",
    "enc_enc_hooks = []\n",
    "enc_dec_hooks = []\n",
    "\n",
    "for i, layer in enumerate(model.decoder.encoder.layers):\n",
    "    hook = AttentionHook()\n",
    "    hook.name = \"SA\"\n",
    "    layer.self_attn.register_forward_hook(hook)\n",
    "    dec_enc_hooks.append(hook)\n",
    "\n",
    "for i, layer in enumerate(model.decoder.decoder.layers):\n",
    "    hook1 = AttentionHook()\n",
    "    hook1.name = \"SA\"\n",
    "    hook2 = AttentionHook()\n",
    "    hook2.name = \"MHA\"\n",
    "    layer.self_attn.register_forward_hook(hook1)\n",
    "    layer.multihead_attn.register_forward_hook(hook2)\n",
    "    dec_dec_hooks.append(hook1)\n",
    "    dec_dec_hooks.append(hook2)\n",
    "\n",
    "for i, layer in enumerate(model.encoder.encoder.layers):\n",
    "    hook = AttentionHook()\n",
    "    hook.name = \"SA\"\n",
    "    layer.self_attn.register_forward_hook(hook)\n",
    "    enc_enc_hooks.append(hook)\n",
    "\n",
    "for i, layer in enumerate(model.encoder.decoder.layers):\n",
    "    hook1 = AttentionHook()\n",
    "    hook1.name = \"SA\"\n",
    "    hook2 = AttentionHook()\n",
    "    hook2.name = \"MHA\"\n",
    "    layer.self_attn.register_forward_hook(hook1)\n",
    "    layer.multihead_attn.register_forward_hook(hook2)\n",
    "    enc_dec_hooks.append(hook1)\n",
    "    enc_dec_hooks.append(hook2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 8])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)\n",
      "2936563\n",
      "2936565\n",
      "tensor(0)\n",
      "tensor([[[-1.4607,  1.4697,  1.3295,  ..., -0.5014, -2.0299,  1.0000],\n",
      "         [-1.4541,  1.5268,  1.3590,  ..., -0.5748, -2.0734,  1.0000],\n",
      "         [-1.4489,  1.5850,  1.3816,  ..., -0.6325, -2.0972,  1.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "i = 20\n",
    "data = train_dataset[i]\n",
    "print(data[\"actions\"].shape)\n",
    "print((~data[\"seq_pad_mask\"]).to(torch.int))\n",
    "# with torch.no_grad():\n",
    "out = model(data,use_precalc=True)\n",
    "\n",
    "print(data[\"actions\"])\n",
    "\n",
    "# # Visualize attention for each layer\n",
    "# for i, hook in enumerate(enc_enc_hooks):\n",
    "#     visualize_attention_weights(hook.attention_weights[0], \"Encoder Encoder\", i+1, hook.name)\n",
    "#     # visualize_attention(hook.attention[0], len(hook.inputs[0][0]), \"Encoder Encoder\", i+1, hook.name)\n",
    "# visualize_attention_weights(torch.mean(torch.stack([x.attention_weights[0] for x in enc_enc_hooks if x.name == \"SA\"], 0), 0), \"Decoder Encoder Mean\", 0, \"SA\")\n",
    "\n",
    "# for i, hook in enumerate(enc_dec_hooks):\n",
    "#     visualize_attention_weights(hook.attention_weights[0], \"Encoder Decoder\", np.ceil((i+1)/2), hook.name)\n",
    "#     # visualize_attention(hook.attention[0], len(hook.inputs[0][0]), \"Encoder Decoder\", i+1, hook.name)\n",
    "# visualize_attention_weights(torch.mean(torch.stack([x.attention_weights[0] for x in enc_dec_hooks if x.name == \"SA\"], 0), 0), \"Encoder Decoder Mean\", 0, \"SA\")\n",
    "# visualize_attention_weights(torch.mean(torch.stack([x.attention_weights[0] for x in enc_dec_hooks if x.name == \"MHA\"], 0), 0), \"Encoder Decoder Mean\", 0, \"MHA\")\n",
    "\n",
    "# for i, hook in enumerate(dec_enc_hooks):\n",
    "#     visualize_attention_weights(hook.attention_weights[0], \"Decoder Encoder\", i+1, hook.name)\n",
    "#     # visualize_attention(hook.attention[0], len(hook.inputs[0][0]), \"Decoder Encoder\", i+1, hook.name)\n",
    "# visualize_attention_weights(torch.mean(torch.stack([x.attention_weights[0] for x in dec_enc_hooks if x.name == \"SA\"], 0), 0), \"Decoder Encoder Mean\", 0, \"SA\")\n",
    "\n",
    "# for i, hook in enumerate(dec_dec_hooks):\n",
    "#     visualize_attention_weights(hook.attention_weights[0], \"Decoder Decoder\", np.ceil((i+1)/2), hook.name)\n",
    "#     # visualize_attention(hook.attention[0], len(hook.inputs[0][0]), \"Decoder Decoder\", i+1, hook.name)    \n",
    "# visualize_attention_weights(torch.mean(torch.stack([x.attention_weights[0] for x in dec_dec_hooks if x.name == \"SA\"], 0), 0), \"Decoder Decoder Mean\", 0, \"SA\")\n",
    "# visualize_attention_weights(torch.mean(torch.stack([x.attention_weights[0] for x in dec_dec_hooks if x.name == \"MHA\"], 0), 0), \"Decoder Decoder Mean\", 0, \"MHA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tskill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
